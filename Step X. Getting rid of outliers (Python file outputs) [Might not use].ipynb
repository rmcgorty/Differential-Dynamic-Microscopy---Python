{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we are getting rid of outliers in the data. These is a decently time consuming portion of the analysis, but it makes the data prettier! :P"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1. Again, we will need to initialize the necessary python modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import io \n",
    "\n",
    "font_plt = {'family': 'serif',\n",
    "            'color':  'darkred',\n",
    "            'weight': 'normal',\n",
    "            'size': 10,\n",
    "            }\n",
    "font_plt_ax = {'family': 'serif',\n",
    "               'color':  'black',\n",
    "               'weight': 'normal',\n",
    "               'size': 10,\n",
    "              }\n",
    "import sys\n",
    "import glob #glob is helpful for searching for filenames or directories\n",
    "sys.path.append('Z:\\\\Code\\\\PythonCode\\\\Differential-Dynamic-Microscopy---Python')\n",
    "import ddm_clean as ddm #this is the module containing the differential dynamic microscopy code\n",
    "import scipy #scientific python\n",
    "import pickle #for saving data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Initialize the dictionary file that will store the tau values that have good fits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allRez = {} #comment out after initializing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Initialize the framerate, dimensions of ROI, pixel size, and define the spatial frequencies. This only needs to be run once at the beginning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framerate = 18.0\n",
    "px = 0.194\n",
    "imDimension = 256\n",
    "q = np.arange(0,imDimension/2)*2*np.pi*(1./(imDimension*(px))) \n",
    "qrange = np.where((q>=0.3)&(q<=3.0)) #this is the q range where the values are typically reasonable!\n",
    "dts = ddm.genLogDist(1,2998,400)\n",
    "times = dts/framerate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4. Load in the '.p' file where the data was saved from step two. This file name might have the video number, the date, and the roi in it so also make sure that those are correctly written in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = '032719'\n",
    "roi = ['0','256','512','768','1024']\n",
    "video = ['1', '2','3','4','5','6','7','8','9','10','11']\n",
    "R = 3 #you can just change this number and it will change the roi for you\n",
    "V = 6\n",
    "\n",
    "data = 'Z:\\\\Folder where data is stored\\\\the allResults folder\\\\NameofFile.p'\n",
    "use = pickle.load(open(data,'rb'))\n",
    "\n",
    "fitparams = use['fitparams_'+video[V]+'_'+roi[R]] #step 2 (the previous code) saves the data with the video number and roi\n",
    "theory = use['theory_'+video[V]+'_'+roi[R]]\n",
    "ravs = use['ravs_'+video[V]+'_'+roi[R]]\n",
    "taus = fitparams[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 5. There is a range of q values that should have reasonable fits for the decay time. We're gonna assume that it is from 0:50, but you can make the range smaller if you want. I do NOT recommend making it any larger!\n",
    "\n",
    "Next you will plot all of the ravs and their fits within the range. You will look at it (pretty much just an estimation) and decide which values have bad fits. Usually it is pretty obvious and easy to pick out. \n",
    "\n",
    "You will write down the bad values in the empty \"markdown\" section after the for loop that plots the ravs. \n",
    "\n",
    "\n",
    "**Remember that python counts from 0, so figure 1 = 0, and figure 50 = 49**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(q[:50])):\n",
    "    fig = plt.figure(figsize=(3,3)); ax = fig.gca();\n",
    "    ax.semilogx(times,ravs[:,i],'ro',alpha=0.4)\n",
    "    ax.plot(times[:len(theory[i,:])], theory[i,:], '-b',lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here you will write down the indices where the theory does not fit the data**\n",
    "\n",
    "Sample: Blank\n",
    "\n",
    "Video 1:\n",
    "\n",
    "roi 0:\n",
    "\n",
    "roi 256:\n",
    "\n",
    "roi 512:\n",
    "\n",
    "roi 768:\n",
    "\n",
    "roi 1024:\n",
    "\n",
    "After you have gone through the plots continue onto the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 6. Copy and past the numbers above into the badvalues array, these are the indices of the decay times that we want to get rid of. We are going to save the decay time values as NAN so that we can have a place holder that will not mess up the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "badvalues = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in badvalues:\n",
    "    taus[j] = np.NAN\n",
    "\n",
    "allRez['NAN_taus_'+video[V]+'_'+roi[R]] = taus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7. Repeat steps 4-6 until you have finished the sample or the video you are interested in \"cleaning up\"\n",
    "\n",
    "Step 8. Save the file with all of the clean decay times as a '.p'. This will be used again later. Also, copy and past all of the indicies you marked as bad in step 5 into a text file, so in case something happens to the data you know which taus are bad already.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(allRez, open('Z:\\\\Data folder\\\\allResults folder\\\\allResults_sample_date_videos_nan_taus.p','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
